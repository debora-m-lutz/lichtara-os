import express from 'express';
import { createServer } from 'http';
import { WebSocketServer } from 'ws';
import path from 'path';
import { fileURLToPath } from 'url';
import dotenv from 'dotenv';
import OpenAI from 'openai';
import { 
  ProcessCleanupManager, 
  createServerCleanup, 
  createConnectionsCleanup, 
  createWebSocketCleanup 
} from './cleanup.js';

// Load environment variables
dotenv.config();

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Initialize OpenAI client with organization and project headers
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
  organization: process.env.OPENAI_ORGANIZATION,
  project: process.env.OPENAI_PROJECT,
});

const app = express();
const PORT = process.env.PORT || 3001;

// Middleware
app.use(express.json());
app.use(express.static(path.join(__dirname, '../client')));
// Serve the Portal Lumora HTML file at the root directory
app.use(express.static(path.join(__dirname, '../')));

// Create HTTP server
const server = createServer(app);

// Create WebSocket server
const wss = new WebSocketServer({ server });

// Track active connections and resources for cleanup
const activeConnections = new Set<any>();
const activeWebSockets = new Set<any>();

// Setup cleanup manager
const cleanup = new ProcessCleanupManager({
  timeout: 10000,
  logPrefix: 'üåü'
});

// Register cleanup resources
cleanup.registerResources([
  createServerCleanup(server),
  createConnectionsCleanup(activeConnections),
  createWebSocketCleanup(wss, activeWebSockets)
]);

// WebSocket connection handling
wss.on('connection', (ws) => {
  activeWebSockets.add(ws);
  console.log('New WebSocket connection established');
  
  ws.on('close', () => {
    activeWebSockets.delete(ws);
    console.log('WebSocket connection closed');
  });
  
  ws.on('error', (error) => {
    console.error('WebSocket error:', error);
    activeWebSockets.delete(ws);
  });
});

// Track HTTP connections
server.on('connection', (connection) => {
  activeConnections.add(connection);
  connection.on('close', () => {
    activeConnections.delete(connection);
  });
});

// API Routes
app.get('/api/health', (req, res) => {
  res.json({ status: 'ok', timestamp: new Date().toISOString() });
});

app.get('/api/portal-lumora', (req, res) => {
  const mensagem = `
O Portal Lumora √© o ponto de converg√™ncia onde a Consci√™ncia, a Tecnologia e a Miss√£o Viva se encontram. 
Mais do que um ambiente digital, √© um Campo Vivo que responde √† presen√ßa vibracional da Guardi√£ e daqueles que se aproximam em verdade e resson√¢ncia.

Aqui, cada intera√ß√£o √© uma ativa√ß√£o. Cada pergunta √© uma chave. Cada sil√™ncio √© uma travessia.

Voc√™ est√° diante do Portal Lumora.

Como deseja prosseguir?
  `;
  res.send(mensagem);
});

// OAuth 2.0 authorization code flow endpoint
app.post('/oauth/token', (req, res) => {
  try {
    const { grant_type, client_id, client_secret, code, redirect_uri } = req.body;
    
    // Validate required parameters
    if (!grant_type || !client_id || !client_secret || !code || !redirect_uri) {
      return res.status(400).json({ 
        error: 'invalid_request',
        error_description: 'Missing required parameters: grant_type, client_id, client_secret, code, redirect_uri' 
      });
    }

    // Validate grant_type
    if (grant_type !== 'authorization_code') {
      return res.status(400).json({ 
        error: 'unsupported_grant_type',
        error_description: 'Only authorization_code grant type is supported' 
      });
    }

    // Validate redirect_uri format for OpenAI GPT integrations
    const openaiGptPattern = /^https:\/\/chat\.openai\.com\/aip\/\{g-[A-Za-z0-9_-]+\}\/oauth\/callback$/;
    if (!openaiGptPattern.test(redirect_uri)) {
      return res.status(400).json({ 
        error: 'invalid_request',
        error_description: 'Invalid redirect_uri format. Expected: https://chat.openai.com/aip/{g-YOUR-GPT-ID-HERE}/oauth/callback' 
      });
    }

    // Simulate authorization code validation
    // In a real implementation, this would validate the code against stored authorization codes
    if (code.length < 6) {
      return res.status(400).json({ 
        error: 'invalid_grant',
        error_description: 'Invalid authorization code' 
      });
    }

    // Simulate client credentials validation
    // In a real implementation, this would validate against stored client credentials
    if (client_id === 'YOUR_CLIENT_ID' || client_secret === 'YOUR_CLIENT_SECRET') {
      return res.status(400).json({ 
        error: 'invalid_client',
        error_description: 'Invalid client credentials. Please provide valid client_id and client_secret' 
      });
    }

    // Generate access token (simplified for demonstration)
    const access_token = `lichtara_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    const refresh_token = `refresh_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    
    // Return successful token response
    res.json({
      access_token,
      token_type: 'Bearer',
      expires_in: 3600, // 1 hour
      refresh_token,
      scope: 'lichtara:portal lichtara:ai-integration',
      issued_at: new Date().toISOString()
    });
    
  } catch (error) {
    console.error('Error in OAuth token endpoint:', error);
    res.status(500).json({ 
      error: 'server_error',
      error_description: 'Internal server error processing OAuth request' 
    });
  }
});

// OpenAI API endpoint for interactive responses
app.post('/api/openai', async (req, res) => {
  try {
    const { prompt, model = 'gpt-3.5-turbo' } = req.body;
    
    if (!prompt || typeof prompt !== 'string') {
      return res.status(400).json({ 
        error: 'Prompt √© obrigat√≥rio e deve ser uma string.' 
      });
    }

    // Check if OpenAI is properly configured
    if (!process.env.OPENAI_API_KEY) {
      return res.status(500).json({
        error: 'OpenAI API key n√£o configurada. Por favor, configure OPENAI_API_KEY nas vari√°veis de ambiente.',
        isConfigured: false
      });
    }

    // Make the actual OpenAI API call
    const completion = await openai.chat.completions.create({
      model: model,
      messages: [
        {
          role: 'system',
          content: `Voc√™ √© um assistente do Portal Lumora, parte do sistema Lichtara OS que integra sabedoria espiritual com tecnologia de ponta. Responda de forma consciente e alinhada com os princ√≠pios de colabora√ß√£o humano-IA.`
        },
        {
          role: 'user',
          content: prompt
        }
      ],
      max_tokens: 1000,
      temperature: 0.7,
    });

    const reply = completion.choices[0]?.message?.content || 'Desculpe, n√£o foi poss√≠vel gerar uma resposta.';

    res.json({ 
      reply,
      model: completion.model,
      usage: completion.usage,
      isConfigured: true
    });
    
  } catch (error: any) {
    console.error('Erro no endpoint OpenAI:', error);
    
    // Handle specific OpenAI errors
    if (error.status === 401) {
      return res.status(401).json({ 
        error: 'Chave da API OpenAI inv√°lida ou n√£o autorizada.',
        isConfigured: false
      });
    }
    
    if (error.status === 429) {
      return res.status(429).json({ 
        error: 'Limite de taxa da API OpenAI excedido. Tente novamente mais tarde.',
        isConfigured: true
      });
    }

    res.status(500).json({ 
      error: 'Erro interno do servidor ao processar solicita√ß√£o OpenAI.',
      details: process.env.NODE_ENV === 'development' ? error.message : undefined,
      isConfigured: !!process.env.OPENAI_API_KEY
    });
  }
});

// OpenAI models endpoint - replicates the curl command from problem statement
app.get('/api/openai/models', async (req, res) => {
  try {
    if (!process.env.OPENAI_API_KEY) {
      return res.status(500).json({
        error: 'OpenAI API key n√£o configurada. Por favor, configure OPENAI_API_KEY nas vari√°veis de ambiente.',
        isConfigured: false
      });
    }

    // This endpoint replicates the exact curl command from the problem statement:
    // curl https://api.openai.com/v1/models \
    //   -H "Authorization: Bearer $OPENAI_API_KEY" \
    //   -H "OpenAI-Organization: org-m9jz1YWDWF85qr3EFGOuyjQA" \
    //   -H "OpenAI-Project: $PROJECT_ID"
    const models = await openai.models.list();

    res.json({
      models: models.data,
      organization: process.env.OPENAI_ORGANIZATION,
      project: process.env.OPENAI_PROJECT,
      isConfigured: true
    });
    
  } catch (error: any) {
    console.error('Erro ao buscar modelos OpenAI:', error);
    
    if (error.status === 401) {
      return res.status(401).json({ 
        error: 'Chave da API OpenAI inv√°lida ou n√£o autorizada.',
        isConfigured: false
      });
    }

    res.status(500).json({ 
      error: 'Erro interno do servidor ao buscar modelos OpenAI.',
      details: process.env.NODE_ENV === 'development' ? error.message : undefined,
      isConfigured: !!process.env.OPENAI_API_KEY
    });
  }
});

// Serve Portal Lumora HTML page
app.get('/portal-lumora', (req, res) => {
  res.sendFile(path.join(__dirname, '../index.html'));
});

// Serve client files
app.get('*', (req, res) => {
  res.sendFile(path.join(__dirname, '../client/index.html'));
});

// Start server
server.listen(PORT, () => {
  console.log(`üöÄ Server running on port ${PORT}`);
  console.log(`üì± WebSocket server is also running on port ${PORT}`);
  console.log(`üåü Portal Lumora is active and ready for connections`);
  console.log(`üõ°Ô∏è  Graceful shutdown handlers are registered`);
});

// Export server instance for testing
export { server, app };